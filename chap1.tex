%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Introduction}
\todo{Very basic Background on parsers, grammars}

\section{Related Work} \label{sec:related}
  The field of parsing is one of the most venerable in computer-science.  Still with us are a variety of parsing approaches born in times of much more severe constraints on memory and processor speed, including various flavors of LR parsers, which apply only to strict subsets of the context-free grammars, to guarantee ability to predict which production applies based on finite look-ahead into a string.  However, despite rumors to the contrary, the field of parsing is far from dead.  In the twentieth century, the functional-programming world experimented with a variety of approaches to \emph{parser combinators}~\cite{pcomb}, where parsers are higher-order functions built from a small set of typed combinators.  In the twenty-first century alone, a number of new parsing approaches have been proposed or popularized, including parsing expression grammars (PEGs)~\cite{PEG}, derivative-based parsing~\cite{Derivs}, and GLL parsers~\cite{GLL}.

  However, our approach is essentially the same, algorithmically, as the one that Ridge demonstrated with a verified parser-combinator system~\cite{Ridge}, taking naive recursive-descent parsing and adding a layer to prune duplicative calls to the parser.  His proof was carried out in HOL4, necessarily without using dependent types.  Our new work may be interesting for the aesthetic appeal of our unusual application of dependent types to get the parser to generate some of its own soundness proof.  Ridge's parser also has worst-case $O(n^5)$ running time in the input-string length.  In the context of our verified implementation, we plan to explore a variety of optimizations based on clever, grammar-specific choices of string-splitter functions, which should have a substantial impact on the run-time cost of parsing some relevant grammars, and which we conjecture will not require any changes to the development presented in this paper.

  A few other past projects have verified parsers with proof assistants, applying to derivative-based parsing~\cite{DerivsCoq} and SLR~\cite{SLR} and LR(1)~\cite{LR1} parsers.  Several projects have used proof assistants to apply verified parsers within larger programming-language tools.  RockSalt~\cite{RockSalt} does run-time memory-safety enforcement for x86 binaries, relying on a verified machine-code parser that applies derivative-based parsing for regular expressions.  The verified Jitawa~\cite{Jitawa} and CakeML~\cite{CakeML} language implementations include verified parsers, handling Lisp and ML languages, respectively.

  Our final parser derivation relies on a relational parametricity property for polymorphic functions in Coq's type theory Gallina.  With Coq as it is today, we need to prove this property manually for each eligible function, even though we can prove metatheoretically that it holds for them all.  Bernardy and Guilhem~\cite{InColor} have shown how to extend type theories with support for materializing ``free theorem'' parametricity facts internally, and we might be able to simplify our implementation using such a feature.
  \todo{Flesh this out}

\section{What's New} \label{sec:new}
  \todo{Fill out what's new}
  
  The goal of this project is to demonstrate a new approach to generating parsers: incrementally building efficient parsers by refinement.
  
  Start with naive recursive-descent parsing, a la {}[Ringe <citation>].  We parameterize the parser on a "splitting oracle", which describes how to recurse. <section citation>  As far as we can tell, the idea of factoring the algorithmic complexity like this is new. <section citation> 
  
  We use fiat to incrementally build efficient parsers by refinement. <section citation>
  
  The idea of reusing the parsing algorithm to prove its own completeness, by parsing parse trees rather than strings, is not found in the literature, to the authors' knowledge. <section citation>
