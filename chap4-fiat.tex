\chapter{Refining Splitters by Fiat}\label{ch:fiat}

%  \begin{itemize} \item  Goals
%    \begin{itemize} \item  Already described parsing, already have goals (build efficient parser) (refresh memory on this, and justify), now describe the tools 
%    \item  Describe why these are the pieces we need 
%    \item  Describe Fiat 
%    \item  Describe Splitter Refinement 
%    \item  Describe Basic Optimizations \end{itemize}
%  \item{} {}[Rehash parsing, rehash goals, intro rest of paper]
%    \begin{itemize} \item  At a Glance 
%      \begin{itemize} \item  
%      \item   \end{itemize} \end{itemize}
%  \item  {}[Justification of tools] What counts as efficient?
%    \begin{itemize} \item  
%      \begin{itemize} \item  <justification> \end{itemize} 
%    \item   \end{itemize}
%  \item  {}[Describe Fiat]
%    \begin{itemize} \item   
%    \item  
%    \item  The Fiat Mindset 
%      \begin{itemize} \item  
%      \item   \end{itemize} 
%    \item   \end{itemize}
%  \item  {}[Basic opt] First optimization: 
%    \begin{itemize} \item   \end{itemize}
%  \item  {}[Basic opt] Intro to next sections
%    \begin{itemize} \item   \end{itemize} \end{itemize}

\section{Splitters at a Glance}
  We have now finished describing the general parsing algorithm, as well as its correctness proofs; we have an algorithm that decides whether or not a given structure can be imposed on any block of unstructured text.  The algorithm is parametrized on an ``oracle'' that describes how to split the string for each rule; essentially all of the algorithmically interesting content is in the splitters.  For the remainder of this thesis, we will focus on how to implement the splitting oracle.  Correctness is not enough, in general; algorithms also need to be fast to use.  We thus focus primarily on efficiency when designing splitting algorithms, and work in a framework that guarantees correctness.
  
  The goals of this work, as mentioned in \autoref{sec:goals}, are to present a framework for constructing proven-correct parsers incrementally and argue for its eventual feasibility.  To this end, we build on the previous work of Fiat~\cite{fiat}, to allow us to build programs incrementally while maintaining correctness guarantees.  This section will describe Fiat and how it is used in this project.  The following sections will focus more on the details of the splitting algorithms and less on Fiat itself.
  
\section{What Counts as Efficient?}
  To guide our implementations, we characterize efficient splitters informally, as follows.  Although our eventual concrete efficiency target is to be competitive with extant open-source JavaScript parsers, when designing algorithms, we aim at the asymptotic efficiency target of linearity in the length of the string.  In practice, the dominating concern is that doubling the length of the string should only double the duration of the parse, and not quadruple it (or more!).  %{}\todo{CITATION NEEDED}
  To be efficient, it suffices to have the splitter return at most one index.  In this case, the parsing time is $\mathcal O($length of string${} \times ($product over all nonterminals of the number of possible rules for that nonterminal$))$.
    
  Here is an example of hitting the worst-case scenario. \todo{Is this actually possible?} % Suppose we have a grammar with one rule for each assignment of $d$ and $d'$ to a decimal digit, of the following template:
%    \begin{center}
%      %\AxiomC{} %\RightLabel{\scriptsize(\str{})}
%      %\UnaryInfC{\str{} $\in$ $\epsilon$}
%    %\DisplayProof\qquad
%      \AxiomC{$s_0$ $\in$ \terminal{\emph{d}}}
%      \AxiomC{$s_1$ $\in$ \terminal{\emph{d}}}
%      \RightLabel{\scriptsize(\nt{\emph{dd}}}
%      \BinaryInfC{\strcat{$s_0$}{$s_1$} $\in$ \nt{\emph{dd}}}
%    \DisplayProof\qquad
%      \AxiomC{$s_0$ $\in$ \nt{\emph{dd}}}
%      \AxiomC{$s_1$ $\in$ \nt{\emph{d'd'}}}
%      \RightLabel{\scriptsize(\nt{\emph{ddd'd'}}}
%      \BinaryInfC{\strcat{$s_0$}{$s_1$} $\in$ \nt{\emph{dddd}}}
%    \DisplayProof
%    \end{center}
%    \begin{center}
%      \AxiomC{$s$ $\in$ \nt{\emph{ddd'd'}}}
%      \RightLabel{\scriptsize(\nt{four-digits})}
%      \UnaryInfC{\strcat{$s_0$}{$s_1$} $\in$ \regex{(ab)$^*$}}
%    \DisplayProof
%    \end{center}

  To avoid hitting this worst-case scenario, we can use a nonterminal-picker, which returns the list of possible production rules for a given string and nonterminal.  As long as it returns at most one possible rule in most cases, in constant time, the parsing time will be $\mathcal O(\text{length of string})$; backtracking will never happen.  This is future work.
  
\section{Introducing Fiat}
  \subsection{Incremental Construction by Refinement}
  Efficiency targets in hand, we move on to incremental construction.  The key idea is that parsing rules tend to fall into clumps that are similar between grammars.  For example, many grammars use delimiters (such as whitespace, commas, or binary operation symbols) as splitting points, but only between well-balanced brackets (such as double quotes, parentheses, or comment markers).  We can take advantage of these similarities by baking the relevant algorithms into basic building blocks, which can then be reused across different grammars.  To allow this reuse, we construct the splitters incrementally, allowing us to deal with different rules in different ways.
  
  The Fiat framework~\cite{fiat} is the scaffolding of our splitter implementations.  As a framework, the goal of Fiat is to enable library writers to construct algorithmic building blocks packaged with correctness guarantees, in such a way that users can easily and mostly automatically make use of these building blocks when they apply. 
  
  \subsection{The Fiat Mindset}
    The correctness guarantees of Fiat are based on specifications in the form of propositions in Gallina, the mathematical language used by Coq.  For example, the specification of a valid \fname{has\_parse} method is that \fname{has\_parse}~~\farg{nt}~~\farg{str}~~=~~\true~~\allowbreak$\longleftrightarrow$\allowbreak~~\fname{inhabited}~~(\indname{ParseTreeOf}~~\farg{nt}~~\farg{s}).  Fiat allows incremental construction of algorithms by providing a language for seamlessly mixing specifications and code.  The language is a light-weight monadic syntax with one extra operator: a nondeterministic choice operator; we define the following combinators:
    \begin{align*}
      &\farg{x} \leftarrow \farg{c};~~\farg{c$'$} && \text{Run \farg{c} and store the result in \farg{x}; continue with \farg{c$'$}, which may mention \farg{x}.} \\
      &\farg{c};;~~\farg{c$'$}&&\text{Run \farg{c}.  If it terminates, throw away the result, and run \farg{c$'$}.} \\
      &\constructorname{ret}~~\farg{x} && \text{Immediately return the value \farg{x}.} \\
      &\{ \farg{x}~|~\farg{P}(\farg{x}) \}&&\text{Nondeterministically choose a value of \farg{x} satisfying \farg{P}.} \\
      &&&\qquad\text{If none exists, the program is considered to not terminate.}
    \end{align*}
    An algorithm starts out as a nondeterministic choice of a value satisfying the specification.  Coding then proceeds by refinement.  Formally, we say that a computation \farg{c$'$} \emph{refines} a computation \farg{c}, written \farg{c$'$} $\subseteq$ \farg{c}, if every value that \farg{c$'$} can compute to, \farg{c} can also compute to.  We freely generate the relation ``the computation \farg{c} can compute to the value \farg{v}'', written \cancomputeto{\farg{c}}{\farg{v}}, by the rules:
    \begin{align*}
      \cancomputeto{\constructorname{ret}~~\farg{v}&}{\farg{v}} \\
      \cancomputeto{\{\farg{x}~|~\farg{P}(\farg{x})\}&}{\farg{v}}\quad\text{iff \farg{v} satisfies \farg{P}} \\
      \cancomputeto{(\farg{c};;~~\farg{c$'$})&}{\farg{v}}\quad\text{iff there is a \farg{v$'$} such that \cancomputeto{\farg{c}}{\farg{v$'$}} and \cancomputeto{\farg{c$'$}}{\farg{v}}} \\
      \cancomputeto{(\farg{x} \leftarrow \farg{c};~~\farg{c$'$}(\farg{x}))&}{\farg{v}}\quad\text{iff there is a \farg{v$'$} such that \cancomputeto{\farg{c}}{\farg{v$'$}} and \cancomputeto{\farg{c$'$}(\farg{v$'$})}{\farg{v}}}
    \end{align*}
    
    In our use case, we express the specification of the splitter as a nondeterministic choice of a list of split locations, such that any splitting location that results in a valid parse tree is contained in the list.  More formally, we can define the proposition
\begin{align*}
  &\fname{split\_list\_is\_complete} ~:~\indname{Grammar}~\to~\indname{String}~\to~\typelist{\indname{Item}}~\to~\typelist{\mathbb{N}}~\to~\Prop \\
  &\fname{split\_list\_is\_complete}~\farg{G}~\farg{str}~\nil~\farg{splits}~=~\False \\
  &\fname{split\_list\_is\_complete} ~\farg{G}~\farg{str}~(\cons{\farg{it}}{\farg{its}}) ~\farg{splits} \\
  &\qquad=~\forall~\farg{n},~\farg{n}<\fname{length}~\farg{str} \\
  &\qquad\qquad\qquad\to~(\fname{has\_parse}~\farg{it}~(\fname{take}~\farg{n}~\farg{str})~\wedge~\fname{has\_parse}~\farg{its}~(\fname{drop}~\farg{n}~\farg{str})) \\
  &\qquad\qquad\qquad\to~\farg{n}\in\farg{splits}
\end{align*}
    where we overload \fname{has\_parse} to apply to items and productions alike.  In practice, we pass the first item and the rest of the items as separate arguments, so that we don't have to deal with the empty list case.
    
    Let \fname{production\_is\_reachable}~\farg{G}~\farg{p} be the proposition that \farg{p} could show up during parsing, i.e., that \farg{p} is a tail of a rule associated to some valid nonterminal in the grammar; we define this by folding over the list of valid nonterminals.  The specification of the splitter, as a nondeterministic computation, for a given grammar \farg{G}, a given string \farg{str}, and a given rule \cons{\farg{it}}{\farg{its}}, is then:
\begin{align*}
& \{~\farg{splits}~:~\indname{list}~{\mathbb{N}} \\
& |~\fname{production\_is\_reachable}~\farg{G}~(\cons{\farg{it}}{\farg{its}})\\
&\phantom{|~}\to~\fname{split\_list\_is\_complete}~\farg{G}~\farg{str}~\farg{it}~\farg{its}~\farg{splits}~\}
\end{align*}
    
    We then refine this into a choice of a splitting location for each rule actually in the grammar (checking for equality with the given rule), and then can refine (implement) the splitter for each rule separately.  For example, for the grammar \regex{(ab)$^*$}, defined to have a single nonterminal \nt{(ab)$^*$} which can either be empty, or be mapped to \terminal{a}~\terminal{b}~\nt{(ab)$^*$}, we would refine this to the computation:\label{sec:if-folding}
\newcommand{\ndcompfor}[3][]{%
#1\{~\farg{splits}~:~\indname{list}~{\mathbb{N}} \\
&\phantom{#1} |~\fname{split\_list\_is\_complete}~\farg{G}~\farg{str}~#2~#3~\farg{splits}~\}
}
\begin{align*}
& \fname{If}~\valuelist{\nt{(ab)\ensuremath{^*}}}~=_p~\cons{\farg{it}}{\farg{its}}~\fname{Then} \\
&\ndcompfor[\qquad]{\nt{(ab)\ensuremath{^*}}}{\nil} \\
& \fname{Else~If}~\valuelist{\terminal{b},~\nt{(ab)\ensuremath{^*}}}~=_p~\cons{\farg{it}}{\farg{its}}~\fname{Then} \\
&\ndcompfor[\qquad]{\terminal{b}}{\valuelist{\nt{(ab)\ensuremath{^*}}}} \\
& \fname{Else~If}~\valuelist{\terminal{a},~\terminal{b},~\nt{(ab)\ensuremath{^*}}}~=_p~\cons{\farg{it}}{\farg{its}}~\fname{Then} \\
&\ndcompfor[\qquad]{\terminal{a}}{\valuelist{\terminal{b},~\nt{(ab)\ensuremath{^*}}}} \\
& \fname{Else} \\
&\qquad\{~\farg{dummy\_splits}~:~\indname{list}~\mathbb{N}~|~\True~\} \\
\end{align*}
       where $=_p$ refers to a Boolean equality test for productions.  Note that in the final case, we permit any list to be picked, because whenever the production we are handling is reachable, the value returned by that case will never be used.
    
       We can now refine each of these cases separately, using \tactic{setoid\_rewrite}; \newtext{this tactic replaces one subterm of your goal with an ``equivalent'' subterm, where the ``equivalence'' can be any transitive relation.  Using \tactic{setoid\_rewrite} allows us to hide the glue required to state our lemmas about computations as wholes, while using them to replace \emph{subterms} of other computations.}  The key to refining each part separately, to making Fiat work, is that the refinement rules package their correctness properties, so users don't have to worry about correctness when programming by refinement.  We use Coq's setoid rewriting machinery to automatically glue together the various correctness proofs when refining only a part of a program.
           
      For example, we might have a lemma \fname{singleton} which says that returning the length of the string is a valid refinement for any rule that has only one nonterminal; its type, for a particular grammar \farg{G}, a particular string \farg{str}, and a particular nonterminal \farg{nt}, would be
\begin{align*}
& \fname{singleton}~\farg{G}~\farg{str}~\farg{nt} \\
& \qquad:~(\fname{ret}~\valuelist{\fname{length}~\farg{str}}) \\
&\qquad~\subseteq\\
&\ndcompfor[\phantom{:~}\qquad]{\nt{\farg{nt}}}{\nil}
\end{align*}
    Then \texttt{\tactic{setoid\_rewrite}~(\fname{singleton}~\termhole~\termhole~\nt{(ab)$^*$})} would refine 
\begin{align*}
& \fname{If}~\valuelist{\nt{(ab)\ensuremath{^*}}}~=_p~\cons{\farg{it}}{\farg{its}}~\fname{Then} \\
&\ndcompfor[\qquad]{\nt{(ab)\ensuremath{^*}}}{\nil} \\
& \fname{Else~If}~\valuelist{\terminal{b},~\nt{(ab)\ensuremath{^*}}}~=_p~\cons{\farg{it}}{\farg{its}}~\fname{Then} \\
&\ndcompfor[\qquad]{\terminal{b}}{\valuelist{\nt{(ab)\ensuremath{^*}}}} \\
& \fname{Else~If}~\valuelist{\terminal{a},~\terminal{b},~\nt{(ab)\ensuremath{^*}}}~=_p~\cons{\farg{it}}{\farg{its}}~\fname{Then} \\
&\ndcompfor[\qquad]{\terminal{a}}{\valuelist{\terminal{b},~\nt{(ab)\ensuremath{^*}}}} \\
& \fname{Else} \\
&\qquad\{~\farg{dummy\_splits}~:~\indname{list}~\mathbb{N}~|~\True~\}
\end{align*}
into
\begin{align*}
& \fname{If}~\valuelist{\nt{(ab)\ensuremath{^*}}}~=_p~\cons{\farg{it}}{\farg{its}}~\fname{Then} \\
&\qquad\fname{ret}~\valuelist{\fname{length}~\farg{str}}\\
& \fname{Else~If}~\valuelist{\terminal{b},~\nt{(ab)\ensuremath{^*}}}~=_p~\cons{\farg{it}}{\farg{its}}~\fname{Then} \\
&\ndcompfor[\qquad]{\terminal{b}}{\valuelist{\nt{(ab)\ensuremath{^*}}}} \\
& \fname{Else~If}~\valuelist{\terminal{a},~\terminal{b},~\nt{(ab)\ensuremath{^*}}}~=_p~\cons{\farg{it}}{\farg{its}}~\fname{Then} \\
&\ndcompfor[\qquad]{\terminal{a}}{\valuelist{\terminal{b},~\nt{(ab)\ensuremath{^*}}}} \\
& \fname{Else} \\
&\qquad\{~\farg{dummy\_splits}~:~\indname{list}~\mathbb{N}~|~\True~\}
\end{align*}
    \newtext{Note that the only change is in the computation returned in the first branch of the conditional.}

    We now describe the refinements that we do within this framework, to implement efficient splitters.
    
\section{Optimizations}
  \subsection{An Easy First Optimization: Indexed Representation of Strings}
    One optimization that is always possible is to represent the current string being parsed in this recursive call as a pair of indices into the original string.  This allows us to optimize the code doing string manipulation, as it will no longer need to copy strings around, only do index arithmetic.
    
    \newtext{This optimization, as well as the trivial optimizations described in \autoref{ch:fixed-length}, are implemented automatically by the initial lines of any parser refinement process in Fiat.}
    
  \subsection{Putting It All Together}
    \newtext{Now that we have the concepts and ideas behind refining parsers, or, more precisely, splitting oracles for parsers, in the Fiat framework, what does the code actually look like?  Every refinement process, which defines a representation for strings, along with a proven-correct method of splitting them, begins with the same code:}
\begin{align*}
& \texttt{\kw{Lemma}~\oftype{\fname{ComputationalSplitter'}}{\fname{FullySharpened}~\coqgroup{\fname{string\_spec}~\farg{G}}}.} \\
& \texttt{\kw{Proof}.} \\
&\qquad\texttt{\tactic{start~honing~parser~using indexed~representation}.} \\ \\
&\qquad\texttt{\tactic{hone~method~"splits"}.} \\
&\qquad\texttt{\{} \\
&\qquad\qquad\texttt{\tactic{simplify~parser~splitter}.}
\end{align*}
      \newtext{The first line of the proof takes care of the switch to using indices into the original string, of replacing the single nondeterministic choice of a complete list of splits with a sequence of \texttt{If} statements returning separate computations for each rule, and of replacing nondeterministic choices with direct return values when such values can be determined by trivial rules (which will be described in \autoref{ch:fixed-length}).  The tactic \tactic{hone method "splits"} says that we want to refine the splitter, rather than, say, the representation of strings that we are using.  The tactic \tactic{simplify parser splitter} performs a number of straightforward and simple optimizations, such as combining nested \texttt{If} statements which return the same value.}

    
  \subsection{Upcoming Optimizations}
    In the next few sections, we build up various strategies for splitters.  Although our eventual target is JavaScript, we cover only a more modest target of very simple arithmetical expressions in this thesis.  We begin by tying up the \regex{(ab)\ensuremath{^*}} grammar, and then moving on to parse numbers, parenthesized numbers, expressions with only numbers and \terminal{+}, and then expressions with numbers, \terminal{+} and parentheses. 
    
