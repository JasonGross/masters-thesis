Master's Thesis

- 1. Intro - background on parsing, grammars
  - Take from ICFP paper?
- 1a. Related work (more serious than ICFP)
- 1b. what's new here?
  - The goal of this project is to demonstrate a new approach to generating parsers: incrementally building efficient parsers by refinement.
    - Start with naive recursive-descent parsing, a la [Ringe <citation>].  We parameterize the parser on a "splitting oracle", which describes how to recurse. <section citation>  As far as we can tell, the idea of factoring the algorithmic complexity like this is new. <section citation>
    - We use fiat to incrementally build efficient parsers by refinement. <section citation>
  - The idea of reusing the parsing algorithm to prove its own completeness, by parsing parse trees rather than strings, is not found in the literature, to the authors' knowledge. <section citation>
- 2. Explanation of CFGs, recursive descent parsing, making it terminating, idea of splitting oracles
  - Take from ICFP paper
  - 2a. Brute force splitter
    - Note that, for soundness and completeness, there is a trivial splitter: it returns a list of all numbers between 0 and the length of the string.  Because the parser terminates no matter what list it is given, and all valid splits are trivially in this list, this splitting "oracle" is enough to fill the hole.  Thus, we can largely separate concerns about correctness and concerns about efficiency.  In sections BLAH BLAH BLAH, we focus only on correctness, we set up the framework we use to achieve efficiency in section BLAH, and we demonstrate the use of the framework in sections BLAH BLAH BLAH.
- 3. soundness and completeness
  - Take from ICFP paper; explain how soundness can be done without parser extensionality, at the cost of algorithmic complexity elsewhere.
- 4. dependently typed parser, parsing parse trees for completeness
  - Take from ICFP paper
- 5. explanation of fiat framework for refining splitters
  - Goals
    - Already described parsing, already have goals (build efficient parser) (refresh memory on this, and justify), now describe the tools
    - Describe why these are the pieces we need
    - Describe Fiat
    - Describe Splitter Refinement
    - Describe Basic Optimizations
  - [Rehash parsing, rehash goals, intro rest of paper]
  - [Remention fiat, splitters]
  - [Justification of tools] Efficiency
    - To be efficient, it suffices to have the splitter return at most one index.  In this case, the parsing time is O(length of string * (product over all nonterminals of the number of possible rules for that nonterminal)).
      - <justification>
    - To cut out (or cut down) the factor of (# of valid nonterminals)!, we can use a nonterminal-picker, which returns the list of possible production rules for a given string and nonterminal.  As long as it returns at most one possible rule in most cases, in constant time, the parsing time will be O(length of string).  This is future work.
  - [Describe Fiat] We present a framework for constructing efficient splitters incrementally, by refinement.  We make use of prior work on the Fiat framework [citation].  To be usable, the parser must be efficient.  To be usable as a library, it is useful to be able to construct the splitters incrementally, so we don't have to do all of the work in one go, and can reuse basic building blocks, automatically.
  - [Describe Splitter] Incremental construction
    - The basic building block of the framework is a possibly nondeterministic computation.  The Fiat language is a standard monad with a special nondeterministic choice operation.  We express the specification of the splitter as a nondeterministic choice of a list of split locations, such that any splitting location that results in a valid parse tree is contained in the list.
    - The development process in the Fiat language consists of replacing nondeterministic choice with successively more computational implementations of the algorithm.  For example, if we are looking to split the string at the location of the first '+' character, we might first pick the list of "valid locations to split at", and then refine that into a computation that picks the location of the first '+', and returns the singleton list containing that, and then replace the remaining bit of nondeterminism with a computation of the location of the first '+'.
      - refinements that preserve correctness
      - explain refinement notation (ask Ben for our standard notation?)
    - Start with nondet. choice of something that is correct; use setoid-rewriting to refine
  - [Basic opt] First optimization: indexed representation of strings
    - One optimization that is always possible is to represent the current string being parsed in this recursive call as a pair of indices into the original string.  This allows us to optimize the code doing string manipulation, as it will no longer need to copy strings around, only do index arithmetic.
  - [Basic opt] Intro to next sections
    - In the next few sections, we build up various strategies for splitters.  Although our eventual target is JavaScript, we cover only a more modest target of very simple arithmetical expressions in this paper.  We begin by tying up the (ab)* grammar, and then moving on to parse numbers, parenthesized numbers, expressions with only numbers and "+", and then expressions with numbers, "+" and parentheses.
    - For each grammar, the Fiat framework presents us with goals describing the unimplemented portion of the splitter for this particular grammar.  For example, the goal for the (ab)* grammar looks like this: <INSERT GOAL>.  To get to this goal, we write this code: <COQ CODE HERE, with comments describing what each line does>  We thus have to describe how to split a string for the rules <RULES HERE>, and provide proofs that these splitting strategies are complete.  We begin the next section with this splitting strategy.
- 6. fixed length nonterminals, parsing (ab)*; parsing #s; parsing #, ()
  - Goals
    - Explore the framework
    - Demonstrate that we can implement the "obvious" rules to handle a large swath of CFG rules
  - [Intro] In this section we explain how to parse grammars such as the grammar for the regular expression (ab)*; the grammar accepting numbers; and the grammar accepting parenthesized numbers.
  - Describing the splitting strategy: if all strings parsed by a given item are the same length, then we can always split the string when faced with that nonterminal.
    - Walk through an example of parsing "abab" as "(ab)*", describing the splitting at each point.
    - Another example: "((123))"
    - For (ab)*, the item "a", and the item "b" only parse strings of length 1.  Thus when asked for the split for "a", then "b(ab)*", we can split after one character, and similarly after "b". 
    - For numbers with parentheses (of which numbers are a subgrammar), digits always have length 1, so we can split after the first character.
  - Implementation as a refinement rule:
    - Describe the obligation Fiat presents us with for the splitter for (#)
    - Describe how each rule is handled
    - For the relevant rules, we can compute the length at compile time.  Here is the algorithm. <Coq code here>
    - To actually make use of this, we must satisfy the correctness criterion.  This is what refinement means.  We relate the length to the parse trees by a few correctness criteria.
      - Note that we need to use only well-founded recursion.
    - We provide a decision procedure for the validity of this rule.
  - In practice, we don't actually need to rewrite it; because it's never suboptimal to apply this rule (returning a single split location is just about the best we can do (TODO: handle invalid parses and backtracking better)), so we do it automatically, baking it into the initial goal, along with the indexed representation change (explain)
- 7. disjoint items, parsing #, +
  - Goals
    - More exploration
    - Demonstrate a slightly less obvious strategy that handles even more rules
  - [Intro]
  - The splitting strategy: if the set of all characters in one item are disjoint from the set of possible first characters of the next item, then we can split at either the first character not in the first set, or at the first character that is in the second set.
    - For example, if the nonterminal "number" accepts {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, and the nonterminal "binop" accepts {+, -}, then we can either look for the first non-digit and split there, or we can look for the first + or -, and split there.
  - Write down the grammars we want to handle.
  - We compute the sets reflectively.  Here is the algorithm.  Again, note the well-founded recursion.  <Coq code here>
  - We relate the computation to the parse trees by a few correctness criteria, similar to above.
    - Describe the structures and lemmas that go into it.
  - This rule is not applied automatically, because we have this choice about what sets to look for.  In the future, we might pick whichever set is smaller, and do that (but perhaps we think one is more likely than the other?)  Instead we use setoid_rewrite, with [reflexivity] to solve the side-conditions.
  - Example: Parse "1+2+3"
- 8. table of next binary operation at the current level, parsing #, +, ()
  - Goals:
    - Hope to show that nontrivial splitting strategies are reasonably expressible, and reusable
    - Demo the main interesting splitting strategy
      - Explain how it can be used
      - Explain the ideas behind the table
      - Explain the way it's implemented
  - [nontrivial] Example grammars we want to handle: #, +, (); S-expressions
  - [nontrivial] Explain commonalities (balance, binops)
  - [idea] Lookup tables, in O(length)
    - The only new rule is when we have pexpr followed by +.
    - The key insight here is that, to know where to split, we need to know where the next "+" at the current level of parenthetization is.
    - Building the table
      - explain rule, keep list of binops at all levels
    - Proving the table correct
      - explain correctness criterion
      - Relation of paren-balanced-hiding on a string to properties of grammar.
  - [explain implementation]
  - [impl detail] Optimization: Compute based on original string, lookup based on indices, don't need to compute substrings.
  - Example: parsing "(1+2)+3"
    - The generated table is
      "5, 1, 0, -, -, 0 .
        , 4, 3, 2, 1
      "
- (Optional: Showing that parser has "reasonable" performance on grammars with non-brute-force splitter (by using arrays and native strings))
- (Really Optional: building parse trees, not just recognizers)
- 9. Future work
  - Grammars and efficiency: The eventual target for this demonstration of the framework is the JavaScript grammar, and we aim to be competitive, performance-wise, with popular open-source JavaScript implementations. <lookup list of JS implementations>  We plan to profile our parser against these on <lookup test suite>
    - Description of anticipated challenges, based on the JavaScript grammar <lookup JS grammar>
  - Generating Parse Trees
    - We plan to eventually generate parse trees, and error messages, rather than just booleans, in the complete pipeline.  We have already demonstrated that this requires only small adjustments to the algorithm in the section on the dependently typed parser.
  - Validating extraction
    - By adapting <Clement's work>, our parsers will be able to be compiled to verified bedrock/assembly, within Coq
  - Esoterica
    - Take from ICFP