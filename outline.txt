Master's Thesis

- 1. Intro - background on parsing, grammars
  - Take from ICFP paper?
- 1a. Related work (more serious than ICFP)
- 1b. what's new here?
  - The goal of this project is to demonstrate a new approach to generating parsers: incrementally building efficient parsers by refinement.
    - Start with naive recursive-descent parsing, a la [Ringe <citation>].  We parameterize the parser on a "splitting oracle", which describes how to recurse. <section citation>  As far as we can tell, the idea of factoring the algorithmic complexity like this is new. <section citation>
    - We use fiat to incrementally build efficient parsers by refinement. <section citation>
  - The idea of reusing the parsing algorithm to prove its own completeness, by parsing parse trees rather than strings, is not found in the literature, to the authors' knowledge. <section citation>
- 2. Explanation of CFGs, recursive descent parsing, making it terminating, idea of splitting oracles
  - Take from ICFP paper
  - 2a. Brute force splitter
    - Note that, for soundness and completeness, there is a trivial splitter: it returns a list of all numbers between 0 and the length of the string.  Because the parser terminates no matter what list it is given, and all valid splits are trivially in this list, this splitting "oracle" is enough to fill the hole.  Thus, we can largely separate concerns about correctness and concerns about efficiency.  In sections BLAH BLAH BLAH, we focus only on correctness, we set up the framework we use to achieve efficiency in section BLAH, and we demonstrate the use of the framework in sections BLAH BLAH BLAH.
- 3. soundness and completeness
  - Take from ICFP paper; explain how soundness can be done without parser extensionality, at the cost of algorithmic complexity elsewhere.
- 4. dependently typed parser, parsing parse trees for completeness
  - Take from ICFP paper
- 5. explanation of fiat framework for refining splitters
  - Goals
    - Already described parsing, already have goals (build efficient parser) (refresh memory on this, and justify), now describe the tools
    - Describe why these are the pieces we need
    - Describe Fiat
    - Describe Splitter Refinement
    - Describe Basic Optimizations
  - [Rehash parsing, rehash goals, intro rest of paper]
    - At a Glance
      - We have now finished describing the general parsing algorithm, as well as its correctness proofs; we have an algorithm, parametrized on an "oracle" that describes how to split the string for each rule, that decides whether or not a given structure can be imposed on any block of unstructured text.  For the remainder of this paper, we will focus on how to implement the splitting oracle.  Correctness is not enough, in general; algorithms also need to be fast to use.  We thus focus primarily on efficiency when designing splitting algorithms.
      - The goals of this work, as mentioned in section [INTRO], are to present a framework for constructing proven-correct parsers incrementally, and argue for its eventual feasability.  To this end, we build on the previous work of Fiat [CITE], to allow us to build programs incrementally while maintaining correctness guarantees.  This section will describe Fiat, and how it is used in this project.  The following sections will focus more on the details of the splitting algorithms, and less on the details of Fiat.
  - [Justification of tools] What counts as efficient?
    - To guide our implementations, we characterize efficient splitters informally, as follows.  Although our eventual concrete efficiency target is to be competitive with extant open source JavaScript parsers, when designing algorithms, we aim at the asymptotic efficiency target of linearity in the length of the string.  In practice, the dominating concern is that doubling the length of the string should only double the duration of the parse, and not quadruple it (or more!).  [CITATION NEEDED]  To be efficient, it suffices to have the splitter return at most one index.  In this case, the parsing time is O(length of string * (product over all nonterminals of the number of possible rules for that nonterminal)). Here is an example of hitting the worst-case scenario: [EXAMPLE HERE]
      - <justification>
    - To avoid hitting this worst-case scenario, we can use a nonterminal-picker, which returns the list of possible production rules for a given string and nonterminal.  As long as it returns at most one possible rule in most cases, in constant time, the parsing time will be O(length of string); backtracking will never happen.  This is future work.
  - [Describe Fiat]
    - Efficiency targets in hand, we move on to incremental construction.  The key idea is that parsing rules tend to fall into clumps that are similar between grammars.  For example, many grammars use delimiters (such as whitespace, commas, or binary operation symbols) as splitting points, but only between well-balanced brackets (such as double quotes, parentheses, or comment markers).  We can take advantage of these similarities by baking the relevant algorithms into basic building blocks, which can then be reused across different grammars.  To allow this reuse, we construct the splitters incrementally, allowing us to deal with different rules in different ways.
    - The Fiat framework [citation] is the scaffolding of our splitter implementations.  As a framework, the goal of Fiat is to enable library-writers to construct algorithmic building blocks packaged with correctness guarantees, in such a way that users can easily and mostly-automatically make use of these building blocks when they apply.
    - The Fiat Mindset
      - The correctness guarantees of Fiat are based on specifications in the form of Gallina propositions.  For example, the specification of a valid has_parse method is that [has_parse str = true <-> there exists a parse tree of str].  Fiat allows incremental construction of algorithms by providing a language for seamlessly mixing specifications and code.  The language is a light-weight monadic syntax with one extra operator: a non-deterministic choice operator.  [DIAGRAM OF SYNTAX]  An algorithm starts out as a nondeterministic choice of a value satisfying the specification.  Coding then proceeds by refinement.  [DIAGRAM DEFINITION OF REFINEMENT]  In our use case, we express the specification of the splitter as a nondeterministic choice of a list of split locations, such that any splitting location that results in a valid parse tree is contained in the list.  We then refine this into a choice of a splitting location for each rule actually in the grammar (checking for equality with the given rule), and then can refine (implement) the splitter for each rule separately.
  - [Describe Splitter] Incremental construction
    - The basic building block of the framework is a possibly nondeterministic computation.  The Fiat language is a standard monad with a special nondeterministic choice operation.  
    - The development process in the Fiat language consists of replacing nondeterministic choice with successively more computational implementations of the algorithm.  For example, if we are looking to split the string at the location of the first '+' character, we might first pick the list of "valid locations to split at", and then refine that into a computation that picks the location of the first '+', and returns the singleton list containing that, and then replace the remaining bit of nondeterminism with a computation of the location of the first '+'.
      - refinements that preserve correctness
      - explain refinement notation (ask Ben for our standard notation?)
    - Start with nondet. choice of something that is correct; use setoid-rewriting to refine
  - [Basic opt] First optimization: indexed representation of strings
    - One optimization that is always possible is to represent the current string being parsed in this recursive call as a pair of indices into the original string.  This allows us to optimize the code doing string manipulation, as it will no longer need to copy strings around, only do index arithmetic.
  - [Basic opt] Intro to next sections
    - In the next few sections, we build up various strategies for splitters.  Although our eventual target is JavaScript, we cover only a more modest target of very simple arithmetical expressions in this paper.  We begin by tying up the (ab)* grammar, and then moving on to parse numbers, parenthesized numbers, expressions with only numbers and "+", and then expressions with numbers, "+" and parentheses.
    - For each grammar, the Fiat framework presents us with goals describing the unimplemented portion of the splitter for this particular grammar.  For example, the goal for the (ab)* grammar looks like this: <INSERT GOAL>.  To get to this goal, we write this code: <COQ CODE HERE, with comments describing what each line does>  We thus have to describe how to split a string for the rules <RULES HERE>, and provide proofs that these splitting strategies are complete.  We begin the next section with this splitting strategy.
- 6. fixed length nonterminals, parsing (ab)*; parsing #s; parsing #, ()
  - Goals
    - Explore the framework
    - Demonstrate that we can implement the "obvious" rules to handle a large swath of CFG rules
  - [Intro] In this section we explain how to parse grammars such as the grammar for the regular expression (ab)*; the grammar accepting numbers; and the grammar accepting parenthesized numbers.
  - Describing the splitting strategy: if all strings parsed by a given item are the same length, then we can always split the string when faced with that nonterminal.
    - Walk through an example of parsing "abab" as "(ab)*", describing the splitting at each point.
    - Another example: "((123))"
    - For (ab)*, the item "a", and the item "b" only parse strings of length 1.  Thus when asked for the split for "a", then "b(ab)*", we can split after one character, and similarly after "b". 
    - For numbers with parentheses (of which numbers are a subgrammar), digits always have length 1, so we can split after the first character.
  - Implementation as a refinement rule:
    - Describe the obligation Fiat presents us with for the splitter for (#)
    - Describe how each rule is handled
    - For the relevant rules, we can compute the length at compile time.  Here is the algorithm. <Coq code here>
    - To actually make use of this, we must satisfy the correctness criterion.  This is what refinement means.  We relate the length to the parse trees by a few correctness criteria.
      - Note that we need to use only well-founded recursion.
    - We provide a decision procedure for the validity of this rule.
  - In practice, we don't actually need to rewrite it; because it's never suboptimal to apply this rule (returning a single split location is just about the best we can do (TODO: handle invalid parses and backtracking better)), so we do it automatically, baking it into the initial goal, along with the indexed representation change (explain)
- 7. disjoint items, parsing #, +
  - Goals
    - More exploration
    - Demonstrate a slightly less obvious strategy that handles even more rules
  - [Intro]
  - The splitting strategy: if the set of all characters in one item are disjoint from the set of possible first characters of the next item, then we can split at either the first character not in the first set, or at the first character that is in the second set.
    - For example, if the nonterminal "number" accepts {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, and the nonterminal "binop" accepts {+, -}, then we can either look for the first non-digit and split there, or we can look for the first + or -, and split there.
  - Write down the grammars we want to handle.
  - We compute the sets reflectively.  Here is the algorithm.  Again, note the well-founded recursion.  <Coq code here>
  - We relate the computation to the parse trees by a few correctness criteria, similar to above.
    - Describe the structures and lemmas that go into it.
  - This rule is not applied automatically, because we have this choice about what sets to look for.  In the future, we might pick whichever set is smaller, and do that (but perhaps we think one is more likely than the other?)  Instead we use setoid_rewrite, with [reflexivity] to solve the side-conditions.
  - Example: Parse "1+2+3"
- 8. table of next binary operation at the current level, parsing #, +, ()
  - Goals:
    - Hope to show that nontrivial splitting strategies are reasonably expressible, and reusable
    - Demo the main interesting splitting strategy
      - Explain how it can be used
      - Explain the ideas behind the table
      - Explain the way it's implemented
  - [nontrivial] Example grammars we want to handle: #, +, (); S-expressions
  - [nontrivial] Explain commonalities (balance, binops)
  - [idea] Lookup tables, in O(length)
    - The only new rule is when we have pexpr followed by +.
    - The key insight here is that, to know where to split, we need to know where the next "+" at the current level of parenthetization is.
    - Building the table
      - explain rule, keep list of binops at all levels
    - Proving the table correct
      - explain correctness criterion
      - Relation of paren-balanced-hiding on a string to properties of grammar.
  - [explain implementation]
  - [impl detail] Optimization: Compute based on original string, lookup based on indices, don't need to compute substrings.
  - Example: parsing "(1+2)+3"
    - The generated table is
      "5, 1, 0, -, -, 0 .
        , 4, 3, 2, 1
      "
- (Optional: Showing that parser has "reasonable" performance on grammars with non-brute-force splitter (by using arrays and native strings))
- (Really Optional: building parse trees, not just recognizers)
- 9. Future work
  - Grammars and efficiency: The eventual target for this demonstration of the framework is the JavaScript grammar, and we aim to be competitive, performance-wise, with popular open-source JavaScript implementations. <lookup list of JS implementations>  We plan to profile our parser against these on <lookup test suite>
    - Description of anticipated challenges, based on the JavaScript grammar <lookup JS grammar>
  - Generating Parse Trees
    - We plan to eventually generate parse trees, and error messages, rather than just booleans, in the complete pipeline.  We have already demonstrated that this requires only small adjustments to the algorithm in the section on the dependently typed parser.
  - Validating extraction
    - By adapting <Clement's work>, our parsers will be able to be compiled to verified bedrock/assembly, within Coq
  - Esoterica
    - Take from ICFP